{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import json\n",
    "from data_utils import *\n",
    "from model import *\n",
    "from algorithm import *\n",
    "import random\n",
    "import os\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this file, decision maker publishes f but the ground-truth h is different. Improvement is measured by h but score increase is measured by f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_idx = [0,3]\n",
    "nc_idx = [1,2]\n",
    "\n",
    "h, f = MLP(5, [16,8,4]), logReg(5)\n",
    "h.load_state_dict(torch.load('h_models/h_hiring_mlp.pth'))\n",
    "f.load_state_dict(torch.load('h_models/h_hiring_lr.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('data/hiring_data_sample.csv')\n",
    "original['z'] = original['age']\n",
    "X_original = original[['education','YearsCode','PreviousSalary','ComputerSkills','z']]\n",
    "data = Hiring(device='cpu', decision=False)\n",
    "X_original = (X_original - data.mean)/data.std_dev\n",
    "X_original = X_original.to_numpy()\n",
    "X_original = torch.Tensor(X_original)\n",
    "\n",
    "We = torch.tensor([1,1,2,2], dtype = torch.float32)\n",
    "\n",
    "efforts, x_star, x_improve = Grad_effort(f, X_original, We, c_idx, nc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(x_improve[0])\n",
    "print(x_star[0])\n",
    "print(X_original[0])\n",
    "print(np.isnan(x_improve.detach().numpy()).any())\n",
    "print(np.isnan(x_star.detach().numpy()).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_qualifications = np.round(h(X_original).detach().numpy(),3).reshape(-1)\n",
    "original_scores = np.round(f(X_original).detach().numpy(),3).reshape(-1)\n",
    "improve_qualifications = np.round(h(x_improve).detach().numpy(),3).reshape(-1)\n",
    "strategy_scores = np.round(f(x_star).detach().numpy(),3).reshape(-1)\n",
    "print(original_qualifications.mean())\n",
    "print(original_scores.mean())\n",
    "print(improve_qualifications.mean())\n",
    "print(strategy_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array(original['z'])\n",
    "\n",
    "# save scores\n",
    "np.save('results/f_MLPLR_hiring_original_scores.npy', original_scores)\n",
    "np.save('results/f_MLPLR_hiring_original_qualifications.npy', original_qualifications)\n",
    "np.save('results/f_MLPLR_hiring_improve_qualifications.npy', improve_qualifications)\n",
    "np.save('results/f_MLPLR_hiring_strategy_scores.npy', strategy_scores)\n",
    "\n",
    "# save efforts\n",
    "np.save('results/f_MLPLR_hiring_efforts.npy', efforts.detach().numpy())\n",
    "\n",
    "# save groupwise scores\n",
    "np.save('results/f_MLPLR_hiring_original_scores_0.npy', original_scores[g==0])\n",
    "np.save('results/f_MLPLR_hiring_original_qualifications_0.npy', original_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_hiring_improve_qualifications_0.npy', improve_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_hiring_strategy_scores_0.npy', strategy_scores[g==0])\n",
    "\n",
    "np.save('results/f_MLPLR_hiring_original_scores_1.npy', original_scores[g==1])\n",
    "np.save('results/f_MLPLR_hiring_original_qualifications_1.npy', original_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_hiring_improve_qualifications_1.npy', improve_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_hiring_strategy_scores_1.npy', strategy_scores[g==1])\n",
    "\n",
    "# save groupwise efforts\n",
    "np.save('results/f_MLPLR_hiring_efforts_0.npy', efforts.detach().numpy()[g==0])\n",
    "np.save('results/f_MLPLR_hiring_efforts_1.npy', efforts.detach().numpy()[g==1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_idx = [0,1]\n",
    "nc_idx = []\n",
    "\n",
    "h, f = MLP(3,[2]), logReg(3)\n",
    "h.load_state_dict(torch.load('h_models/h_law_mlp.pth'))\n",
    "f.load_state_dict(torch.load('h_models/h_law_lr.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('data/bar_pass_data_sample.csv')\n",
    "original['z'] = original['sex']\n",
    "X_original = original[['ugpa','lsat','z']]\n",
    "data = LawDataset(device='cpu', decision=False)\n",
    "X_original = (X_original - data.mean)/data.std_dev\n",
    "X_original = X_original.to_numpy()\n",
    "X_original = torch.Tensor(X_original)\n",
    "\n",
    "# simulate best response\n",
    "We = torch.tensor([0.5,0.5], dtype = torch.float32)\n",
    "\n",
    "efforts, x_star, x_improve = Grad_effort(f, X_original, We, c_idx, nc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(x_improve[1])\n",
    "print(x_star[1])\n",
    "print(X_original[1])\n",
    "print(np.isnan(x_improve.detach().numpy()).any())\n",
    "print(np.isnan(x_star.detach().numpy()).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_qualifications = np.round(h(X_original).detach().numpy(),3).reshape(-1)\n",
    "original_scores = np.round(f(X_original).detach().numpy(),3).reshape(-1)\n",
    "improve_qualifications = np.round(h(x_improve).detach().numpy(),3).reshape(-1)\n",
    "strategy_scores = np.round(f(x_star).detach().numpy(),3).reshape(-1)\n",
    "\n",
    "print(original_qualifications.mean())\n",
    "print(original_scores.mean())\n",
    "print(improve_qualifications.mean())\n",
    "print(strategy_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array(original['z'])\n",
    "\n",
    "# save scores\n",
    "np.save('results/f_MLPLR_law_original_scores.npy', original_scores)\n",
    "np.save('results/f_MLPLR_law_original_qualifications.npy', original_qualifications)\n",
    "np.save('results/f_MLPLR_law_improve_qualifications.npy', improve_qualifications)\n",
    "np.save('results/f_MLPLR_law_strategy_scores.npy', strategy_scores)\n",
    "\n",
    "# save efforts\n",
    "np.save('results/f_MLPLR_law_efforts.npy', efforts.detach().numpy())\n",
    "\n",
    "# save groupwise scores\n",
    "np.save('results/f_MLPLR_law_original_scores_0.npy', original_scores[g==1])\n",
    "np.save('results/f_MLPLR_law_original_qualifications_0.npy', original_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_law_improve_qualifications_0.npy', improve_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_law_strategy_scores_0.npy', strategy_scores[g==1])\n",
    "\n",
    "np.save('results/f_MLPLR_law_original_scores_1.npy', original_scores[g==2])\n",
    "np.save('results/f_MLPLR_law_original_qualifications_1.npy', original_qualifications[g==2])\n",
    "np.save('results/f_MLPLR_law_improve_qualifications_1.npy', improve_qualifications[g==2])\n",
    "np.save('results/f_MLPLR_law_strategy_scores_1.npy', strategy_scores[g==2])\n",
    "\n",
    "# save groupwise efforts\n",
    "np.save('results/f_MLPLR_law_efforts_0.npy', efforts.detach().numpy()[g==1])\n",
    "np.save('results/f_MLPLR_law_efforts_1.npy', efforts.detach().numpy()[g==2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit\n",
    "\n",
    "- specify stategic indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_idx = [2,3]\n",
    "nc_idx = [0,4,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the decision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "h, f = MLP(10,[64,16,4]), logReg(10)\n",
    "h.load_state_dict(torch.load('h_models/h_credit_MLP.pth'))\n",
    "f.load_state_dict(torch.load('h_models/h_credit_lr.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simulate best responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CreditDataset(device = 'cpu', decision=False)\n",
    "original = pd.read_csv('data/balanced_test_dataset.csv')\n",
    "original['z'] = np.where(original['age'] > 35, 0, 1)\n",
    "X_original = original.drop(columns = ['age','question', 'qualification_status'])\n",
    "X_original = (X_original - data.mean)/data.std_dev\n",
    "X_original = X_original.to_numpy()\n",
    "X_original = torch.Tensor(X_original)\n",
    "\n",
    "# simulate best response\n",
    "We = torch.tensor([0.5,0.5,2,2,2], dtype = torch.float32)\n",
    "\n",
    "efforts, x_star, x_improve = Grad_effort(f, X_original, We, c_idx, nc_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(x_improve[0])\n",
    "print(x_star[0])\n",
    "print(X_original[0])\n",
    "print(np.isnan(x_improve.detach().numpy()).any())\n",
    "print(np.isnan(x_star.detach().numpy()).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get score increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_qualifications = np.round(h(X_original).detach().numpy(),3).reshape(-1)\n",
    "original_scores = np.round(f(X_original).detach().numpy(),3).reshape(-1)\n",
    "improve_qualifications = np.round(h(x_improve).detach().numpy(),3).reshape(-1)\n",
    "strategy_scores = np.round(f(x_star).detach().numpy(),3).reshape(-1)\n",
    "\n",
    "print(original_qualifications.mean())\n",
    "print(original_scores.mean())\n",
    "print(improve_qualifications.mean())\n",
    "print(strategy_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array(original['z'])\n",
    "\n",
    "# save scores\n",
    "np.save('results/f_MLPLR_credit_original_scores.npy', original_scores)\n",
    "np.save('results/f_MLPLR_credit_original_qualifications.npy', original_qualifications)\n",
    "np.save('results/f_MLPLR_credit_improve_qualifications.npy', improve_qualifications)\n",
    "np.save('results/f_MLPLR_credit_strategy_scores.npy', strategy_scores)\n",
    "\n",
    "# save efforts\n",
    "np.save('results/f_MLPLR_credit_efforts.npy', efforts.detach().numpy())\n",
    "\n",
    "# save groupwise scores\n",
    "np.save('results/f_MLPLR_credit_original_scores_0.npy', original_scores[g==0])\n",
    "np.save('results/f_MLPLR_credit_original_qualifications_0.npy', original_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_credit_improve_qualifications_0.npy', improve_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_credit_strategy_scores_0.npy', strategy_scores[g==0])\n",
    "\n",
    "np.save('results/f_MLPLR_credit_original_scores_1.npy', original_scores[g==1])\n",
    "np.save('results/f_MLPLR_credit_original_qualifications_1.npy', original_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_credit_improve_qualifications_1.npy', improve_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_credit_strategy_scores_1.npy', strategy_scores[g==1])\n",
    "\n",
    "# save groupwise efforts\n",
    "np.save('results/f_MLPLR_credit_efforts_0.npy', efforts.detach().numpy()[g==0])\n",
    "np.save('results/f_MLPLR_credit_efforts_1.npy', efforts.detach().numpy()[g==1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACSIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_idx = [0,1]\n",
    "nc_idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, f = MLP(4,[16,8,4]), logReg(4)\n",
    "h.load_state_dict(torch.load('h_models/h_income_mlp.pth'))\n",
    "f.load_state_dict(torch.load('h_models/h_income_lr.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('data/ACSIncome_sample_raw.csv')\n",
    "original['z'] = np.where(original['AGEP'] > 35, 0, 1)\n",
    "X_original = original[['SCHL','WKHP','SEX','z']]\n",
    "X_original = X_original.to_numpy()\n",
    "X_original = torch.Tensor(X_original)\n",
    "\n",
    "\n",
    "# simulate best response\n",
    "We = torch.tensor([1,2], dtype = torch.float32)\n",
    "\n",
    "efforts, x_star, x_improve = Grad_effort(f, X_original, We, c_idx, nc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(x_improve[1])\n",
    "print(x_star[1])\n",
    "print(X_original[1])\n",
    "print(np.isnan(x_improve.detach().numpy()).any())\n",
    "print(np.isnan(x_star.detach().numpy()).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_qualifications = np.round(h(X_original).detach().numpy(),3).reshape(-1)\n",
    "original_scores = np.round(f(X_original).detach().numpy(),3).reshape(-1)\n",
    "improve_qualifications = np.round(h(x_improve).detach().numpy(),3).reshape(-1)\n",
    "strategy_scores = np.round(f(x_star).detach().numpy(),3).reshape(-1)\n",
    "\n",
    "print(original_qualifications.mean())\n",
    "print(original_scores.mean())\n",
    "print(improve_qualifications.mean())\n",
    "print(strategy_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array(original['z'])\n",
    "\n",
    "# save scores\n",
    "np.save('results/f_MLPLR_income_original_scores.npy', original_scores)\n",
    "np.save('results/f_MLPLR_income_original_qualifications.npy', original_qualifications)\n",
    "np.save('results/f_MLPLR_income_improve_qualifications.npy', improve_qualifications)\n",
    "np.save('results/f_MLPLR_income_strategy_scores.npy', strategy_scores)\n",
    "\n",
    "# save efforts\n",
    "np.save('results/f_MLPLR_income_efforts.npy', efforts.detach().numpy())\n",
    "\n",
    "# save groupwise scores\n",
    "np.save('results/f_MLPLR_income_original_scores_0.npy', original_scores[g==0])\n",
    "np.save('results/f_MLPLR_income_original_qualifications_0.npy', original_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_income_improve_qualifications_0.npy', improve_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_income_strategy_scores_0.npy', strategy_scores[g==0])\n",
    "\n",
    "np.save('results/f_MLPLR_income_original_scores_1.npy', original_scores[g==1])\n",
    "np.save('results/f_MLPLR_income_original_qualifications_1.npy', original_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_income_improve_qualifications_1.npy', improve_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_income_strategy_scores_1.npy', strategy_scores[g==1])\n",
    "\n",
    "# save groupwise efforts\n",
    "np.save('results/f_MLPLR_income_efforts_0.npy', efforts.detach().numpy()[g==0])\n",
    "np.save('results/f_MLPLR_income_efforts_1.npy', efforts.detach().numpy()[g==1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACSPAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_idx = [1,2]\n",
    "nc_idx = [0]\n",
    "h, f = MLP(4,[16,8,4]), logReg(4)\n",
    "h.load_state_dict(torch.load('h_models/h_pap_mlp.pth'))\n",
    "f.load_state_dict(torch.load('h_models/h_pap_lr.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('data/ACSPAP_sample.csv')\n",
    "original['z'] = np.where(original['AGEP'] > 35, 0, 1)\n",
    "X_original = original[['WKHP','SCHL','PINCP','z']]\n",
    "data = ACSPAP(device='cpu', decision=False)\n",
    "X_original = (X_original - data.mean)/data.std_dev\n",
    "X_original = X_original.to_numpy()\n",
    "X_original = torch.Tensor(X_original)\n",
    "\n",
    "# simulate best response\n",
    "We = torch.tensor([1,1,2], dtype = torch.float32)\n",
    "delta = 0.3\n",
    "\n",
    "efforts, x_star, x_improve = Grad_effort(f, X_original, We, c_idx, nc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(x_improve[1])\n",
    "print(x_star[1])\n",
    "print(X_original[1])\n",
    "print(np.isnan(x_improve.detach().numpy()).any())\n",
    "print(np.isnan(x_star.detach().numpy()).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_qualifications = np.round(h(X_original).detach().numpy(),3).reshape(-1)\n",
    "original_scores = np.round(f(X_original).detach().numpy(),3).reshape(-1)\n",
    "improve_qualifications = np.round(h(x_improve).detach().numpy(),3).reshape(-1)\n",
    "strategy_scores = np.round(f(x_star).detach().numpy(),3).reshape(-1)\n",
    "\n",
    "print(original_qualifications.mean())\n",
    "print(original_scores.mean())\n",
    "print(improve_qualifications.mean())\n",
    "print(strategy_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array(original['z'])\n",
    "\n",
    "# save scores\n",
    "np.save('results/f_MLPLR_pap_original_scores.npy', original_scores)\n",
    "np.save('results/f_MLPLR_pap_original_qualifications.npy', original_qualifications)\n",
    "np.save('results/f_MLPLR_pap_improve_qualifications.npy', improve_qualifications)\n",
    "np.save('results/f_MLPLR_pap_strategy_scores.npy', strategy_scores)\n",
    "\n",
    "# save efforts\n",
    "np.save('results/f_MLPLR_pap_efforts.npy', efforts.detach().numpy())\n",
    "\n",
    "# save groupwise scores\n",
    "np.save('results/f_MLPLR_pap_original_scores_0.npy', original_scores[g==0])\n",
    "np.save('results/f_MLPLR_pap_original_qualifications_0.npy', original_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_pap_improve_qualifications_0.npy', improve_qualifications[g==0])\n",
    "np.save('results/f_MLPLR_pap_strategy_scores_0.npy', strategy_scores[g==0])\n",
    "\n",
    "np.save('results/f_MLPLR_pap_original_scores_1.npy', original_scores[g==1])\n",
    "np.save('results/f_MLPLR_pap_original_qualifications_1.npy', original_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_pap_improve_qualifications_1.npy', improve_qualifications[g==1])\n",
    "np.save('results/f_MLPLR_pap_strategy_scores_1.npy', strategy_scores[g==1])\n",
    "\n",
    "# save groupwise efforts\n",
    "np.save('results/f_MLPLR_pap_efforts_0.npy', efforts.detach().numpy()[g==0])\n",
    "np.save('results/f_MLPLR_pap_efforts_1.npy', efforts.detach().numpy()[g==1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
